{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2thsEMniTNVN"
      },
      "source": [
        "Runtime > Change Runtime Type > Select GPU > Save\n",
        "\n",
        "Then run this cell to make pytorch use the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPR22OeOWMTD",
        "outputId": "d270414c-e2b5-4a35-a288-eeb54060b0bd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> DETERMINE EXECUTION DEVICE <<<<<\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print('device count', torch.cuda.device_count())\n",
        "print('current', torch.cuda.current_device())\n",
        "print('GPU', torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy2tl5c8TBcN"
      },
      "source": [
        "Zip the data folder and upload as data.zip, then run this cell to unzip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8waoTk2JfwtL",
        "outputId": "8854b033-127e-451c-de60-3d9b2aff267c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> COLAB UNZIPPING <<<<<\n",
        "(optional)\n",
        "\"\"\"\n",
        "#!unzip data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chLbxbdcTsr4"
      },
      "source": [
        "Run the next 4 cells to start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptGozU-DYGFP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> HELPER FUNCTIONS <<<<<\n",
        "\"\"\"\n",
        "from matplotlib import pyplot as plt\n",
        "def show_image_mask(img, mask, cmap='gray'): # visualisation\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img, cmap=cmap)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(mask, cmap=cmap)\n",
        "    plt.axis('off')\n",
        "    plt.show() # draw the images immediatelly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk6PzD7aYGyf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> DATA LOADERS <<<<<\n",
        "(including fix for linux glob)\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "import natsort\n",
        "\n",
        "class TrainDataset(data.Dataset):\n",
        "    def __init__(self, root=''):\n",
        "        super(TrainDataset, self).__init__()\n",
        "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
        "        #self.img_files = self.img_files[0:10] # only using part of the dataset\n",
        "        self.mask_files = []             \n",
        "        for img_path in self.img_files:\n",
        "            basename = os.path.basename(img_path)\n",
        "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
        "            \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "            img_path = self.img_files[index]\n",
        "            mask_path = self.mask_files[index]\n",
        "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "            return torch.from_numpy(data).float(), torch.from_numpy(label).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "class TestDataset(data.Dataset):\n",
        "    def __init__(self, root=''):\n",
        "        super(TestDataset, self).__init__()\n",
        "        #self.img_files = glob(os.path.join(root,'image','*.png'))\n",
        "        self.img_files = natsort.natsorted(glob(os.path.join(root,'image','*.png')))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "            img_path = self.img_files[index]\n",
        "            print(\"get \"+img_path)\n",
        "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            return torch.from_numpy(data).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __insert__(self, newimgfiles, newmaskfiles): \n",
        "        #self.img_files = torch.cat[self.img_files, newimgfiles]\n",
        "        #self.mask_files = torch.cat[self.mask_files, newmaskfiles]\n",
        "        return 1\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIpT63JS12r9"
      },
      "source": [
        "U-Net Refined Version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrX6pTCp146N"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> MODEL DEFINITION <<<<<\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        kernel_size = 5\n",
        "        padding = 2\n",
        "        dropout_rate = 0.5\n",
        "\n",
        "        # Down Layers\n",
        "\n",
        "        self.enc_11 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=1,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.enc_12 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=64,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ])\n",
        "\n",
        "        self.enc_21 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=64,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.enc_22 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ])\n",
        "\n",
        "        self.enc_31 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.enc_32 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)\n",
        "        ])\n",
        "\n",
        "        self.enc_41 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.enc_42 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ])\n",
        "\n",
        "        self.enc_51 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=1024,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ])\n",
        "\n",
        "        self.enc_52 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=1024,\n",
        "                      out_channels=1024,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)])\n",
        "\n",
        "        # Up Layers\n",
        "\n",
        "        # 4u for if bilinear, or 4t for convolution\n",
        "        self.dec_4t = nn.Sequential(*[nn.ConvTranspose2d(in_channels=1024, out_channels=1024, kernel_size=2, stride=2)])\n",
        "        self.dec_4u = nn.Sequential(*[nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)])\n",
        "\n",
        "        self.dec_41 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=1024,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ])\n",
        "\n",
        "        self.dec_42 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=1024,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_rate)\n",
        "        ])\n",
        "\n",
        "        self.dec_3t = nn.Sequential(*[nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=2, stride=2)])\n",
        "        self.dec_3u = nn.Sequential(*[nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)])\n",
        "\n",
        "        self.dec_31 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.dec_32 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)\n",
        "        ])\n",
        "\n",
        "        self.dec_2t = nn.Sequential(*[nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=2, stride=2)])\n",
        "        self.dec_2u = nn.Sequential(*[nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)])\n",
        "\n",
        "        self.dec_21 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.dec_22 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)])\n",
        "\n",
        "        self.dec_1t = nn.Sequential(*[nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=2, stride=2)])\n",
        "        self.dec_1u = nn.Sequential(*[nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)])\n",
        "\n",
        "        self.dec_11 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)])\n",
        "\n",
        "        self.dec_12 = nn.Sequential(*[\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.5)])\n",
        "\n",
        "        self.final = nn.Conv2d(64, 4, kernel_size=1)\n",
        "\n",
        "        self.init_kaiming_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc11 = self.enc_11(x)\n",
        "        # print(\"\\nEnc1: \", enc11.shape)\n",
        "        enc12 = self.enc_12(enc11)\n",
        "        pool1 = F.max_pool2d(enc12, kernel_size=2, stride=2)\n",
        "\n",
        "        enc21 = self.enc_21(pool1)\n",
        "        # print(\"Enc2: \", enc21.shape)\n",
        "        enc22 = self.enc_22(enc21)\n",
        "        pool2 = F.max_pool2d(enc22, kernel_size=2, stride=2)\n",
        "\n",
        "        enc31 = self.enc_31(pool2)\n",
        "        # print(\"Enc3: \", enc31.shape)\n",
        "        enc32 = self.enc_32(enc31)\n",
        "        pool3 = F.max_pool2d(enc32, kernel_size=2, stride=2)\n",
        "\n",
        "        enc41 = self.enc_41(pool3)\n",
        "        # print(\"Enc3: \", enc41.shape)\n",
        "        enc42 = self.enc_42(enc41)\n",
        "        pool4 = F.max_pool2d(enc42, kernel_size=2, stride=2)\n",
        "\n",
        "        enc51 = self.enc_51(pool4)\n",
        "        # print(\"Enc3: \", enc51.shape)\n",
        "        enc52 = self.enc_52(enc51)\n",
        "\n",
        "        dec4t = self.dec_4u(enc52)\n",
        "        # print(\"Dec4t: \", dec4t.shape)\n",
        "        dec41 = self.dec_41(dec4t)\n",
        "        # print(\"Dec41: \", dec41.shape)\n",
        "        dec4c = torch.cat([dec41, enc42], dim=1)\n",
        "        # print(\"Dec4c: \", dec4c.shape)\n",
        "        dec42 = self.dec_42(dec4c)\n",
        "        # print(\"Dec42: \", dec42.shape)\n",
        "\n",
        "        dec3t = self.dec_3u(enc42)\n",
        "        # print(\"Dec3t: \", dec3t.shape)\n",
        "        dec31 = self.dec_31(dec3t)\n",
        "        # print(\"Dec31: \", dec31.shape)\n",
        "        dec3c = torch.cat([dec31, enc32], dim=1)\n",
        "        # print(\"Dec3c: \", dec3c.shape)\n",
        "        dec32 = self.dec_32(dec3c)\n",
        "        # print(\"Dec32: \", dec32.shape)\n",
        "\n",
        "        dec2t = self.dec_2u(dec32)\n",
        "        # print(\"Dec2t: \", dec2t.shape)\n",
        "        dec21 = self.dec_21(dec2t)\n",
        "        # print(\"Dec21: \", dec21.shape)\n",
        "        dec2c = torch.cat([dec21, enc22], dim=1)\n",
        "        # print(\"Dec2c: \", dec2c.shape)\n",
        "        dec22 = self.dec_22(dec2c)\n",
        "        # print(\"Dec22: \", dec22.shape)\n",
        "\n",
        "        dec1t = self.dec_1u(dec22)\n",
        "        # print(\"Dec1t: \", dec1t.shape)\n",
        "        dec11 = self.dec_11(dec1t)\n",
        "        # print(\"Dec11: \", dec11.shape)\n",
        "        dec1c = torch.cat([dec11, enc12], dim=1)\n",
        "        # print(\"Dec1c: \", dec1c.shape)\n",
        "        dec12 = self.dec_12(dec1c)\n",
        "        # print(\"Dec12: \", dec12.shape)\n",
        "\n",
        "        return self.final(dec12)\n",
        "\n",
        "    def init_kaiming_weights(self):\n",
        "        # Encoder 1\n",
        "        nn.init.kaiming_normal_(self.enc_11[0].weight)\n",
        "        nn.init.kaiming_normal_(self.enc_12[0].weight)\n",
        "        # Encoder 2\n",
        "        nn.init.kaiming_normal_(self.enc_21[0].weight)\n",
        "        nn.init.kaiming_normal_(self.enc_22[0].weight)\n",
        "        # Encoder 3\n",
        "        nn.init.kaiming_normal_(self.enc_31[0].weight)\n",
        "        nn.init.kaiming_normal_(self.enc_32[0].weight)\n",
        "\n",
        "        # Encoder 4\n",
        "        nn.init.kaiming_normal_(self.enc_41[0].weight)\n",
        "        nn.init.kaiming_normal_(self.enc_42[0].weight)\n",
        "\n",
        "        # Encoder 5\n",
        "        nn.init.kaiming_normal_(self.enc_51[0].weight)\n",
        "        nn.init.kaiming_normal_(self.enc_52[0].weight)\n",
        "\n",
        "        # Decoder 4\n",
        "        nn.init.kaiming_normal_(self.dec_41[0].weight)\n",
        "        nn.init.kaiming_normal_(self.dec_42[0].weight)\n",
        "\n",
        "        # Decoder 3\n",
        "        nn.init.kaiming_normal_(self.dec_31[0].weight)\n",
        "        nn.init.kaiming_normal_(self.dec_32[0].weight)\n",
        "\n",
        "        # Decoder 2\n",
        "        nn.init.kaiming_normal_(self.dec_21[0].weight)\n",
        "        nn.init.kaiming_normal_(self.dec_22[0].weight)\n",
        "\n",
        "        # Decoder 1\n",
        "        nn.init.kaiming_normal_(self.dec_11[0].weight)\n",
        "        nn.init.kaiming_normal_(self.dec_12[0].weight)\n",
        "\n",
        "        # Final\n",
        "        nn.init.kaiming_normal_(self.final.weight)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVBuLS2TDLT4"
      },
      "source": [
        "Train and Eval things: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2RcIhZ2u_WE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> DICE SCORE COMPUTATION <<<<<\n",
        "(modified from tutorial, added optional printing, removed background score)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "def categorical_dice(mask1, mask2, label_class=1):\n",
        "    \"\"\"\n",
        "    Dice score of a specified class between two volumes of label masks.\n",
        "    (classes are encoded but by label class number not one-hot )\n",
        "    Note: stacks of 2D slices are considered volumes.\n",
        "\n",
        "    Args:\n",
        "        mask1: N label masks, numpy array shaped (H, W, N)\n",
        "        mask2: N label masks, numpy array shaped (H, W, N)\n",
        "        label_class: the class over which to calculate dice scores\n",
        "\n",
        "    Returns:\n",
        "        volume_dice\n",
        "    \"\"\"\n",
        "    mask1_pos = (mask1 == label_class).astype(np.float32)\n",
        "    mask2_pos = (mask2 == label_class).astype(np.float32)\n",
        "    denom = (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
        "    if(int(denom) == 0):\n",
        "        return 0\n",
        "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
        "    return dice\n",
        "\n",
        "def dice_class_score(mask1, mask2):\n",
        "    dice_scores = [\n",
        "        categorical_dice(mask1, mask2, 0),\n",
        "        categorical_dice(mask1, mask2, 1),\n",
        "        categorical_dice(mask1, mask2, 2),\n",
        "        categorical_dice(mask1, mask2, 3)\n",
        "    ]\n",
        "    return dice_scores\n",
        "\n",
        "def average_dice(mask1, mask2, verbose):\n",
        "    dice_scores = dice_class_score(mask1, mask2)\n",
        "    if(verbose):\n",
        "        for i in range(len(dice_scores)):\n",
        "            print(\"=> Class {} = {}\".format(i+1,dice_scores[i]))   # i+1 because not including background class\n",
        "\n",
        "    total_dice = sum(dice_scores) / len(dice_scores)\n",
        "    return total_dice\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsWjSjYIDKwl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> TRAINING & EVAL FUNCTION <<<<<\n",
        "\"\"\"\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def run_validation(model,dataloader):\n",
        "    model.eval() # switch model to evaluation mode\n",
        "    dices = []\n",
        "    with torch.no_grad():\n",
        "       \n",
        "        # Fetch images and labels.\n",
        "        for iteration, sample in enumerate(dataloader):\n",
        "            img, mask = sample\n",
        "\n",
        "            # forward\n",
        "            img = img.unsqueeze(1)\n",
        "            img = img.to(device)    # move to gpu during training/validation\n",
        "            outputs = model(img)\n",
        "\n",
        "            mask = mask.type(torch.LongTensor)\n",
        "            # convert output to predicted class so it can be visualised\n",
        "            mask_pred = torch.argmax(outputs, dim=1).detach().cpu()\n",
        "\n",
        "            numsamples = mask.shape[0]  # how many images to dice score for\n",
        "            for i in range(numsamples):\n",
        "                dice = dice_class_score(mask[i,...].numpy(), mask_pred[i,...].numpy())\n",
        "                dices.append(dice)\n",
        "    return dices\n",
        "\n",
        "def avg_and_save_validation(filename,dices):\n",
        "    numclasses = len(dices[0])\n",
        "    totals = [0 for i in range(numclasses)]\n",
        "    for scores in dices:\n",
        "        for i in range(len(scores)):\n",
        "            totals[i] += scores[i]\n",
        "    \n",
        "    numdices = len(dices)\n",
        "    classavg_dices = [t / numdices for t in totals]\n",
        "    dice_score = sum(classavg_dices) / len(classavg_dices)\n",
        "\n",
        "    stringdices = [str(d) for d in classavg_dices]\n",
        "    with open(filename,\"a\") as f:\n",
        "        line = \", \".join(stringdices)\n",
        "        print(line)\n",
        "        f.write(line+\"\\n\")\n",
        "    return dice_score\n",
        "    \n",
        "\n",
        "def train_eval():\n",
        "    model = UNet()\n",
        "    # Define the model\n",
        "    model = UNet()\n",
        "    epochs = 200\n",
        "    lr = 0.01\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    optimiser = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # CUDA Setup\n",
        "    device = torch.device(\"cpu\")\n",
        "    if (torch.cuda.is_available()):\n",
        "        print(\"CUDA\")\n",
        "        device = torch.device(\"cuda\")\n",
        "    # Pass the model and loss function to the device\n",
        "    model = model.to(device)\n",
        "    loss_fn = loss_fn.to(device)\n",
        "\n",
        "    # Setup DataLoaders for both the training and validation data\n",
        "    train_data_path = './data/train'\n",
        "    validate_data_path = './data/val'\n",
        "    num_workers = 4\n",
        "    batch_size = 10\n",
        "    # Seperate batch_size cause I was struggling to index masks correctly and too lazy to change it now\n",
        "    val_batch_size = 2\n",
        "    train_set = TrainDataset(train_data_path)\n",
        "    validate_set = TrainDataset(validate_data_path)\n",
        "    validation_data_loader = DataLoader(dataset=validate_set, num_workers=num_workers, batch_size=val_batch_size,\n",
        "                                        shuffle=True)\n",
        "    training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size,\n",
        "                                      shuffle=True)\n",
        "\n",
        "\n",
        "    print('=> Training Data Length:' , len(training_data_loader))\n",
        "    best_dice = 0\n",
        "    dice_score = 0\n",
        "\n",
        "    train_log = []\n",
        "    validation_log = []\n",
        "\n",
        "    CSV_HEADER = \"class0, class1, class2, class3\\n\"\n",
        "    with open(\"trainlog.csv\",\"w\") as f:\n",
        "            f.write(CSV_HEADER)\n",
        "    with open(\"validlog.csv\",\"w\") as f:\n",
        "            f.write(CSV_HEADER)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        model.train()\n",
        "        ##### TRAIN CYCLE #####\n",
        "        # Fetch images and labels.\n",
        "        for iteration, sample in enumerate(training_data_loader):\n",
        "            \n",
        "            # Read in sample image and mask\n",
        "            img, mask = sample\n",
        "            \n",
        "            # Setup image so its in the format the model is expecting\n",
        "            inp_img = img.view(batch_size, 1, 96, 96)\n",
        "\n",
        "            inp_img = inp_img.to(device)\n",
        "\n",
        "            optimiser.zero_grad()\n",
        "\n",
        "            mask_pred = model(inp_img)\n",
        "\n",
        "            mask_pred = mask_pred.view(batch_size, 4, 96, 96)\n",
        "\n",
        "            # Loss expects long target so change it here\n",
        "            mask = mask.long()\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            loss = loss_fn(mask_pred, mask)\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "        \n",
        "        ##### VALIDATE EVERY EPOCH #####\n",
        "        \n",
        "        dices = run_validation(model,training_data_loader)\n",
        "        print(\"Epoch:\",epoch,\"train raw: \",end='')\n",
        "        dice_score = avg_and_save_validation(\"trainlog.csv\",dices)\n",
        "        print(\"Epoch:\",epoch, \"training dice:  \", dice_score)\n",
        "\n",
        "        \n",
        "\n",
        "        dices = run_validation(model,validation_data_loader)\n",
        "        print(\"Epoch:\",epoch,\"valid raw: \",end='')\n",
        "        dice_score = avg_and_save_validation(\"validlog.csv\",dices)\n",
        "        print(\"Epoch:\",epoch, \"validation dice:\", dice_score)\n",
        "\n",
        "        ##### SAVE BEST #####\n",
        "        if(dice_score > best_dice):\n",
        "            print(\"=> New Personal Best! {}\".format(dice_score))\n",
        "            print(\"=> Saving...\")\n",
        "            best_dice = dice_score\n",
        "            with open(\"./best_dice.txt\",\"w\") as f:\n",
        "                f.write(\"avg_dice={}\\n\".format(best_dice))\n",
        "                f.write(\"epoch={}\\n\".format(epoch))\n",
        "                f.write(\"totalepochs={}\\n\".format(epochs))\n",
        "                f.write(\"lr={}\\n\".format(lr))\n",
        "                f.write(\"train_data={}\\n\".format(train_data_path))\n",
        "                f.write(\"validation_data={}\\n\".format(validate_data_path))\n",
        "                f.write(\"train_batch_size={}\\n\".format(batch_size))\n",
        "            PATH = './trained_best_dice.pth'.format(epoch)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            print(\"=> Saved Personal Best\")\n",
        "\n",
        "\n",
        "        # Every 25 epochs calculate loss on validation set\n",
        "        if epoch % 25 == 0 and epoch != 0:\n",
        "            # Save the model for later testing\n",
        "           # PATH = './final/UNet/UNet_Adam_1e-5_' + str(epoch) + '.pth'\n",
        "            PATH = './trained_{0}e.pth'.format(epoch)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-TQ2XXwETc4",
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> RUN TRAINING WITH EVALUATION <<<<<\n",
        "\"\"\"\n",
        "train_eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> LOAD SAVED MODEL <<<<<\n",
        "\"\"\"\n",
        "model = UNet()\n",
        "#model.load_state_dict(torch.load(\"sgd_training/trained_99e.pth\"))  # this is cool\n",
        "model.load_state_dict(torch.load(\"trained_best_dice.pth\"))\n",
        "#model.load_state_dict(torch.load(\"trained_25e.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7ckfhRuvDYz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        ">>>>> COMPUTE VALIDATION DICE SCORE <<<<<\n",
        "(should be almost identical to the one stated in best_dice.txt)\n",
        "\"\"\"\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_path = './data/val'\n",
        "num_workers = 0\n",
        "batch_size = 2\n",
        "val_set = TrainDataset(data_path)\n",
        "val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "total_dice = 0.0\n",
        "\n",
        "model.eval() # switch model to evaluation mode\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    dices = []\n",
        "    # Fetch images and labels.\n",
        "    for iteration, sample in enumerate(val_data_loader):\n",
        "        img, mask = sample \n",
        "\n",
        "        # forward\n",
        "        img = img.unsqueeze(1)\n",
        "        img = img.to(device)\n",
        "        outputs = model(img)\n",
        "\n",
        "        mask = mask.type(torch.LongTensor)\n",
        "        \n",
        "        # convert output to predicted class so it can be visualised\n",
        "        mask_pred = torch.argmax(outputs, dim=1).detach().cpu()\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            print('+++++')\n",
        "            show_image_mask(mask_pred[i,...].squeeze(), mask[i,...].squeeze())\n",
        "            dice = average_dice(mask[i,...].numpy(), mask_pred[i,...].numpy(),True)\n",
        "            dices.append(dice)\n",
        "            print('avg dice=', dice)\n",
        "        \n",
        "    avg = sum(dices) / len(dices)\n",
        "    print(\"<<<<<>>>>>\")\n",
        "    print('Done val! DICE: ', avg) # 20 images in val dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WAS6nLAvQ_e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> CREATE MASKS <<<<<\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# In this block you are expected to write code to load saved model and deploy it to all data in test set to \n",
        "# produce segmentation masks in png images valued 0,1,2,3, which will be used for the submission to Kaggle.\n",
        "data_path = './data/test'\n",
        "num_workers = 0\n",
        "batch_size = 1\n",
        "\n",
        "test_set = TestDataset(data_path)\n",
        "test_data_loader = DataLoader(dataset=test_set, num_workers=num_workers,batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model.cpu()\n",
        "model.eval() # switch model to evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # Fetch images and labels.\n",
        "    for iteration, sample in enumerate(test_data_loader):\n",
        "        img = sample\n",
        "\n",
        "        # forward\n",
        "        img = img.unsqueeze(1)\n",
        "        outputs = model(img)\n",
        "\n",
        "        # convert output to predicted class so it can be visualised\n",
        "        pred_class = torch.argmax(outputs, dim=1)\n",
        "        #show_image_mask(img[0,...].squeeze(), pred_class[0,...].squeeze())\n",
        "        \n",
        "        # save predictions\n",
        "        mask_filename = 'cmr{0}_mask.png'.format(iteration + 121)\n",
        "        print('saving as', mask_filename)\n",
        "        \n",
        "        pred_img = pred_class[0,...].squeeze().numpy()\n",
        "        cv2.imwrite(os.path.join('./data/test/mask', mask_filename), pred_img)\n",
        "        \n",
        "print('Done test!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> DISPLAY MASKS <<<<<\n",
        "\"\"\"\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_path = './data/test'\n",
        "num_workers = 0\n",
        "batch_size = 1\n",
        "val_set = TrainDataset(data_path)\n",
        "val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "total_dice = 0.0\n",
        "\n",
        "model.eval() # switch model to evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # Fetch images and labels.\n",
        "    for iteration, sample in enumerate(val_data_loader):\n",
        "        img = sample[0].squeeze()\n",
        "        mask = sample[1].squeeze()\n",
        "        show_image_mask(img,mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ycjr1s-PvWLS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        ">>>>> CREATE SUBMISSION <<<<<\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def rle_encoding(x):\n",
        "    '''\n",
        "    *** Credit to https://www.kaggle.com/rakhlin/fast-run-length-encoding-python ***\n",
        "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
        "    Returns run length as list\n",
        "    '''\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "\n",
        "def submission_converter(mask_directory, path_to_save):\n",
        "    writer = open(os.path.join(path_to_save, \"submission.csv\"), 'w')\n",
        "    writer.write('id,encoding\\n')\n",
        "\n",
        "    files = os.listdir(mask_directory)\n",
        "\n",
        "    for file in files:\n",
        "        name = file[:-4]\n",
        "        mask = cv2.imread(os.path.join(mask_directory, file), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        mask1 = (mask == 1)\n",
        "        mask2 = (mask == 2)\n",
        "        mask3 = (mask == 3)\n",
        "\n",
        "        encoded_mask1 = rle_encoding(mask1)\n",
        "        encoded_mask1 = ' '.join(str(e) for e in encoded_mask1)\n",
        "        encoded_mask2 = rle_encoding(mask2)\n",
        "        encoded_mask2 = ' '.join(str(e) for e in encoded_mask2)\n",
        "        encoded_mask3 = rle_encoding(mask3)\n",
        "        encoded_mask3 = ' '.join(str(e) for e in encoded_mask3)\n",
        "\n",
        "        writer.write(name + '1,' + encoded_mask1 + \"\\n\")\n",
        "        writer.write(name + '2,' + encoded_mask2 + \"\\n\")\n",
        "        writer.write(name + '3,' + encoded_mask3 + \"\\n\")\n",
        "\n",
        "    writer.close()\n",
        "    \n",
        "submission_converter('./data/test/mask', './')\n",
        "print('Submission done!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "UNET GOOGLE COLLAB GPU-James",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
