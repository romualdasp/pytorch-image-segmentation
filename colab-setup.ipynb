{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2thsEMniTNVN"
      },
      "source": [
        "Runtime > Change Runtime Type > Select GPU > Save\n",
        "\n",
        "Then run this cell to make pytorch use the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPR22OeOWMTD",
        "outputId": "7cf1fa7e-3e42-4f1b-ed89-daf50cc14b78"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print('device count', torch.cuda.device_count())\n",
        "print('current', torch.cuda.current_device())\n",
        "print('GPU', torch.cuda.get_device_name(0))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "device count 1\n",
            "current 0\n",
            "GPU Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy2tl5c8TBcN"
      },
      "source": [
        "Zip the data folder and upload as data.zip, then run this cell to unzip it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8waoTk2JfwtL"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chLbxbdcTsr4"
      },
      "source": [
        "Run the next 4 cells to start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptGozU-DYGFP"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def show_image_mask(img, mask, cmap='gray'): # visualisation\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img, cmap=cmap)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(mask, cmap=cmap)\n",
        "    plt.axis('off')\n",
        "    plt.show() # draw the images immediatelly"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk6PzD7aYGyf"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "class TrainDataset(data.Dataset):\n",
        "    def __init__(self, root=''):\n",
        "        super(TrainDataset, self).__init__()\n",
        "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
        "        #self.img_files = self.img_files[0:10] # only using part of the dataset\n",
        "        self.mask_files = []\n",
        "        for img_path in self.img_files:\n",
        "            basename = os.path.basename(img_path)\n",
        "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
        "            \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "            img_path = self.img_files[index]\n",
        "            mask_path = self.mask_files[index]\n",
        "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "            return torch.from_numpy(data).float(), torch.from_numpy(label).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "class TestDataset(data.Dataset):\n",
        "    def __init__(self, root=''):\n",
        "        super(TestDataset, self).__init__()\n",
        "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "            img_path = self.img_files[index]\n",
        "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            return torch.from_numpy(data).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4BSBylbYJu-"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SimpleHybrid(nn.Module): # Define your model\n",
        "    def __init__(self):\n",
        "        super(SimpleHybrid, self).__init__()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(  1, 128, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        \n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners = False)\n",
        "        \n",
        "        self.conv7 = nn.Conv2d(512, 256, 3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "\n",
        "        self.conv9  = nn.Conv2d(256, 128, 3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        \n",
        "        self.convscores = nn.Conv2d(128, 4, 3, padding=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # fill in the forward function for your model here\n",
        "        \n",
        "        x = F.selu(self.conv1(x))\n",
        "        x = F.selu(self.conv2(x))\n",
        "        x = F.selu(self.conv2(x))\n",
        "        x = F.selu(self.conv2(x))\n",
        "        x = F.selu(self.conv2(x))\n",
        "        \n",
        "        x = self.pool(x) # now at 48x48 resolution\n",
        "        \n",
        "        x = F.selu(self.conv3(x))\n",
        "        x = F.selu(self.conv4(x))\n",
        "        x = F.selu(self.conv4(x))\n",
        "        x = F.selu(self.conv4(x))\n",
        "        x = F.selu(self.conv4(x))\n",
        "\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.selu(self.conv5(x))\n",
        "        x = F.selu(self.conv6(x))\n",
        "        x = F.selu(self.conv6(x))\n",
        "        x = F.selu(self.conv6(x))\n",
        "        x = F.selu(self.conv6(x))\n",
        "\n",
        "        #if using ConvTranspose2d, then x = self.upsample(x, output_size=(96,96))\n",
        "        x = self.upsample(x)\n",
        "        \n",
        "        x = F.selu(self.conv7(x))\n",
        "        x = F.selu(self.conv8(x))\n",
        "        x = F.selu(self.conv8(x))\n",
        "        x = F.selu(self.conv8(x))\n",
        "        x = F.selu(self.conv8(x))\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        \n",
        "        x = F.selu(self.conv9(x))\n",
        "        x = F.selu(self.conv10(x))\n",
        "        x = F.selu(self.conv10(x))\n",
        "        x = F.selu(self.conv10(x))\n",
        "        x = F.selu(self.conv10(x))\n",
        "        \n",
        "        x = self.convscores(x) # CrossEntropyLoss does softmax inside it\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = SimpleHybrid() # We can now create a model using your defined segmentation model\n",
        "model.to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "Loss = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.8, 0.9), eps=1e-08, weight_decay=0)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.8)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM-6DGHhYMed"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_path = './data/train'\n",
        "num_workers = 4\n",
        "batch_size = 4\n",
        "train_set = TrainDataset(data_path)\n",
        "training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "save_network = True\n",
        "\n",
        "model.train() # switch model to training mode\n",
        "\n",
        "for epoch in range(1000):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    # Fetch images and labels.  \n",
        "    for iteration, sample in enumerate(training_data_loader):\n",
        "        # img, mask = sample \n",
        "        img, mask = sample[0].to(device), sample[1].to(device)\n",
        "\n",
        "        #visualise only the first image in a batch\n",
        "        #show_image_mask(img[0,...].squeeze(), mask[0,...].squeeze())\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        img = img.unsqueeze(1) # model expects data in precise format\n",
        "        outputs = model(img)\n",
        "        \n",
        "        # print(img.size(), '...', mask.size())\n",
        "        # print(outputs.size(), pred_class.size(), outputs.dtype, pred_class.dtype, mask.dtype)\n",
        "        \n",
        "        #mask = mask.type(torch.LongTensor)\n",
        "        mask = mask.type(torch.cuda.LongTensor)\n",
        "        \n",
        "        #print('...>', mask[0,48,48], '...', pred_class[0,0,48,48], '...', outputs[0,:,48,48])\n",
        "        \n",
        "        # loss + backward + optimize\n",
        "        loss = Loss(outputs, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print stats\n",
        "        running_loss += loss.item()\n",
        "        if iteration == 0:\n",
        "            print('epoch ', epoch, ' iteration ', iteration, ' loss ', running_loss / 24)\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            # draw predicted images next to ground truth masks\n",
        "            pred_class = torch.argmax(outputs, dim=1)\n",
        "            pred_class = pred_class.unsqueeze(1)\n",
        "            show_image_mask(pred_class[0,...].squeeze().cpu(), mask[0,...].squeeze().cpu())\n",
        "            \n",
        "        if save_network:\n",
        "            if epoch % 50 == 49:\n",
        "                PATH = './trained_{0}e.pth'.format(epoch)\n",
        "                torch.save(model.state_dict(), PATH)\n",
        "            \n",
        "print('Done training!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}